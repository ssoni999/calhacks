# Data Engineer - Big Data & Analytics

## Company Overview
We are a data-driven technology company leveraging analytics and machine learning to make intelligent decisions. Our data team builds robust pipelines and infrastructure that process terabytes of data daily, enabling insights that drive business growth.

## Role Overview
We're looking for an experienced Data Engineer to design and build scalable data pipelines, optimize data infrastructure, and enable our analytics and machine learning teams. You'll work with large-scale distributed systems and cutting-edge big data technologies.

## Key Responsibilities

### Data Pipeline Development
- Design and implement scalable ETL/ELT pipelines processing terabytes of data
- Build real-time and batch data processing systems
- Develop data ingestion pipelines from various sources
- Implement data transformation and enrichment logic
- Optimize pipeline performance and resource utilization

### Data Infrastructure
- Design and maintain data lake and data warehouse architectures
- Build and optimize data storage solutions (S3, HDFS, data warehouses)
- Implement data partitioning and indexing strategies
- Manage cloud data infrastructure (Redshift, BigQuery, Snowflake)
- Design data models for analytics and reporting

### Data Quality & Governance
- Implement data quality checks and validation frameworks
- Establish data lineage and metadata management
- Ensure data security and access controls
- Monitor data pipeline health and SLAs
- Document data schemas and pipeline architectures

### Collaboration & Support
- Work with data scientists to productionize ML models
- Collaborate with analysts on data requirements
- Support business intelligence and reporting needs
- Partner with engineering on system integration
- Enable self-service analytics capabilities

### Performance & Optimization
- Optimize Spark jobs and SQL queries for performance
- Implement caching and materialized views
- Tune data warehouse performance
- Monitor and reduce data processing costs
- Design efficient data distribution strategies

## Required Qualifications

### Experience
- 4+ years of data engineering experience
- Strong experience building data pipelines at scale
- Proven track record with big data technologies
- Experience with cloud data platforms

### Technical Skills - Programming
- Strong programming skills in Python or Scala
- Proficiency in SQL and query optimization
- Experience with data processing frameworks
- Knowledge of functional programming concepts
- Understanding of distributed computing principles

### Technical Skills - Big Data
- Strong experience with Apache Spark (PySpark or Scala)
- Knowledge of distributed processing frameworks
- Experience with Hadoop ecosystem (HDFS, Hive, Pig)
- Familiarity with stream processing (Kafka, Flink, Spark Streaming)
- Understanding of MapReduce and parallel processing

### Technical Skills - Data Warehouses
- Experience with cloud data warehouses (Redshift, BigQuery, Snowflake)
- Strong SQL skills and query optimization
- Knowledge of data modeling (star schema, snowflake schema)
- Experience with columnar storage formats (Parquet, ORC)
- Understanding of data warehouse best practices

### Technical Skills - Cloud & Tools
- Experience with AWS data services (S3, EMR, Glue, Redshift, Athena)
- Knowledge of workflow orchestration (Airflow, Luigi, Prefect)
- Familiarity with version control (Git) and CI/CD
- Experience with containerization (Docker)
- Understanding of infrastructure as code

### Technical Skills - Data Quality
- Experience with data quality frameworks (Great Expectations, dbt)
- Knowledge of data testing and validation
- Understanding of data observability
- Familiarity with metadata management
- Experience with data lineage tools

### Database & Storage
- Strong knowledge of relational databases (PostgreSQL, MySQL)
- Experience with NoSQL databases (MongoDB, Cassandra)
- Understanding of database indexing and optimization
- Knowledge of data compression and encoding
- Familiarity with time-series databases

### Soft Skills
- Strong analytical and problem-solving skills
- Excellent communication abilities
- Ability to work with non-technical stakeholders
- Attention to detail and data accuracy
- Passion for data and analytics

## Preferred Qualifications

### Advanced Experience
- Experience with real-time streaming architectures
- Knowledge of change data capture (CDC) patterns
- Experience with data mesh or data fabric architectures
- Familiarity with data lakehouse concepts (Delta Lake, Iceberg)
- Experience with graph databases (Neo4j)

### Machine Learning Infrastructure
- Experience building ML pipelines and feature stores
- Knowledge of MLOps practices and tools
- Familiarity with model serving infrastructure
- Understanding of feature engineering at scale
- Experience with ML frameworks (TensorFlow, PyTorch)

### Specialized Skills
- Experience with data visualization tools (Tableau, Looker, Metabase)
- Knowledge of BI platforms and reporting
- Familiarity with data governance tools (Collibra, Alation)
- Experience with data anonymization and privacy
- Understanding of data compliance (GDPR, CCPA)

### Leadership & Impact
- Experience mentoring data engineers
- Track record of improving data infrastructure
- Contributions to open-source data projects
- Technical writing or conference speaking
- Advanced degree in relevant field (Master's, PhD)

## Education
- Bachelor's degree in Computer Science, Data Science, Engineering, or related field
- Master's degree in Data Science, Statistics, or related field preferred
- Equivalent practical experience will be considered

## Technical Stack
- **Languages:** Python, Scala, SQL
- **Big Data:** Apache Spark, Hadoop, Kafka, Airflow
- **Data Warehouses:** Snowflake, Redshift, BigQuery
- **Cloud:** AWS (S3, EMR, Glue, Redshift, Athena), GCP
- **Databases:** PostgreSQL, MongoDB, Redis, Elasticsearch
- **Orchestration:** Apache Airflow, Luigi, Prefect
- **Data Quality:** Great Expectations, dbt
- **Formats:** Parquet, ORC, Avro, JSON, CSV
- **Tools:** Jupyter, Pandas, NumPy, PySpark

## What We Offer
- Competitive salary ($130,000 - $200,000) + equity
- Comprehensive health benefits
- Flexible remote work options
- Learning budget for courses and certifications
- Access to cutting-edge data technologies
- Collaborative data-driven culture
- Opportunity to work with massive datasets
- Career growth in data engineering and analytics

## Keywords for Matching
Data Engineer, Data Engineering, ETL, ELT, Big Data, Apache Spark, PySpark, Python, Scala, SQL, Data Pipeline, Data Warehouse, Snowflake, Redshift, BigQuery, AWS, GCP, Airflow, Kafka, Hadoop, Data Lake, PostgreSQL, MongoDB, Data Quality, Data Modeling, Data Architecture, Analytics, Machine Learning, MLOps, Distributed Systems, Cloud, Database, NoSQL, Real-time Processing, Stream Processing, Master's Degree, Data Science, MIT, Stanford

---

**Location:** Boston, MA or Remote (US)  
**Employment Type:** Full-time  
**Experience Level:** Mid to Senior (4-8 years)  
**Salary Range:** $130,000 - $200,000 + equity

